{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b7a30-c590-4c81-9fb8-6a6437fa5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/facebookresearch/seamless_communication/tree/main#quick-start\n",
    "'''\n",
    "!git clone https://github.com/facebookresearch/seamless_communication.git\n",
    "%cd seamless_communication\n",
    "pwd\n",
    "pip install .\n",
    "'''\n",
    "#https://huggingface.co/facebook/seamless-m4t-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbc8d3a-fc02-4431-a64b-a98d325219c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 25 18:57:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    24W / 250W |      0MiB / 12288MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72844982-cf33-4bfc-b4f4-209d16a92dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "VAdepthENV               /home/013907062/.conda/envs/VAdepthENV\n",
      "cmpe249                  /home/013907062/.conda/envs/cmpe249\n",
      "env_onmttf               /home/013907062/.conda/envs/env_onmttf\n",
      "hawaii                   /home/013907062/.conda/envs/hawaii\n",
      "hawaii_hf             *  /home/013907062/.conda/envs/hawaii_hf\n",
      "koen_base                /home/013907062/.conda/envs/koen_base\n",
      "newDepth                 /home/013907062/.conda/envs/newDepth\n",
      "seamless                 /home/013907062/.conda/envs/seamless\n",
      "test                     /home/013907062/.conda/envs/test\n",
      "wmt_infer                /home/013907062/.conda/envs/wmt_infer\n",
      "base                     /opt/ohpc/pub/apps/anaconda/3.9\n",
      "stylegan2                /opt/ohpc/pub/apps/anaconda/3.9/envs/stylegan2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb991f3b-d864-45ee-943b-a1be90866946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                         2.1.0+cu118\n",
      "torchaudio                    2.1.0+cu118\n",
      "torcheval                     0.0.7\n",
      "torchvision                   0.16.0+cu118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npip install torch==2.0.0\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip list | grep torch\n",
    "\n",
    "'''\n",
    "pip install torch==2.0.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dceb24c-8075-4c2d-b380-c0da228d1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d40850-9a15-4f9e-879c-2f9ad228acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seamless_communication.models.inference import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8818af-3a55-4e8a-b7da-d4a347296d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of the model 'seamlessM4T_medium'. Set `force=True` to download again.\n",
      "Using the cached tokenizer of the model 'seamlessM4T_medium'. Set `force=True` to download again.\n",
      "Using the cached checkpoint of the model 'vocoder_36langs'. Set `force=True` to download again.\n",
      "/home/013907062/.conda/envs/hawaii_hf/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Translator object with a multitask model, vocoder on the GPU.\n",
    "'''\n",
    "download model in CPU head node\n",
    "'''\n",
    "translator = Translator(\"seamlessM4T_medium\", vocoder_name_or_card=\"vocoder_36langs\", device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c64cf8d0-0521-4fb3-a761-98f1c60efacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/013907062/OpenNMT-tf/scripts/seamless'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2046ab50-b88e-4695-a3e2-0560401a2719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mental health includes our emotional, psychological, and social well-being\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "\n",
    "input_text = \"Kasama sa kalusugan ng isip ang ating emosyonal, sikolohikal, at panlipunang kagalingan\"\n",
    "tgt_lang = 'eng'\n",
    "src_lang = 'tgl'\n",
    "expected_text = \"Mental health includes our emotional, psychological, and social well-being\"\n",
    "\n",
    "translated_text, _, _ = translator.predict(input_text, \"t2tt\", tgt_lang, src_lang=src_lang)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92546a2-945d-402f-b912-064ed9af82c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] HFSeamlessM4T init...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of the model 'seamlessM4T_medium'. Set `force=True` to download again.\n",
      "Using the cached tokenizer of the model 'seamlessM4T_medium'. Set `force=True` to download again.\n",
      "Using the cached checkpoint of the model 'vocoder_36langs'. Set `force=True` to download again.\n"
     ]
    }
   ],
   "source": [
    "#TEST API\n",
    "\n",
    "import LLMTranslation\n",
    "myTranslator = LLMTranslation.SeamlessMT4(device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c34ac86-b23e-4537-9e59-f356e4417543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kumusta ka na, ngayon ay isang araw na may araw!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = myTranslator.translateText(\"How are you, Today? It's a sunny day!\", \"eng\", \"tgl\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809af852-5ee3-4eaa-8623-0317759b05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jcblaise/roberta-tagalog-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedc0ac-f1f0-479a-81b5-35c9c1f120ea",
   "metadata": {},
   "source": [
    "## Download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8524296e-4d59-4f5f-b567-e253b6b704c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/013907062/.conda/envs/hawaii_hf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, list_datasets\n",
    "# you can find available language pairs here: https://huggingface.co/datasets/opus_books (no pair with en-tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8abe31-2436-49d4-be89-4b8ff27d4609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-25 19:21:29--  https://tinyurl.com/flores200dataset\n",
      "Resolving tinyurl.com (tinyurl.com)... 172.67.1.225, 104.20.139.65, 104.20.138.65, ...\n",
      "Connecting to tinyurl.com (tinyurl.com)|172.67.1.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://dl.fbaipublicfiles.com/nllb/flores200_dataset.tar.gz [following]\n",
      "--2023-10-25 19:21:29--  https://dl.fbaipublicfiles.com/nllb/flores200_dataset.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.238.206, 99.84.238.162, 99.84.238.154, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.238.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25585843 (24M) [application/x-tar]\n",
      "Saving to: ‘flores200_dataset.tar.gz’\n",
      "\n",
      "100%[======================================>] 25,585,843   107MB/s   in 0.2s   \n",
      "\n",
      "2023-10-25 19:21:29 (107 MB/s) - ‘flores200_dataset.tar.gz’ saved [25585843/25585843]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://github.com/facebookresearch/flores/tree/main/flores200\n",
    "'''\n",
    "#!wget --trust-server-names https://tinyurl.com/flores200dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2849aa-5f8c-4e98-8638-5335a4a694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 406/406 [00:00<00:00, 1.50MB/s]\n",
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/357k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 357k/357k [00:01<00:00, 286kB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 203.61it/s]\n",
      "Generating train split: 100%|██████████| 7305/7305 [00:00<00:00, 470622.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "raw_jmbt22_datasets = load_dataset(\"jmbt22/tatoeba-en-tgl\")\n",
    "#in CPU head node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba6a0b5-aa7c-47ae-9bb1-3106eb5cf15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation.en', 'translation.tl'],\n",
       "        num_rows: 7305\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_jmbt22_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "999011dc-c30c-436b-9d6f-1b1d8f8e92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset to use GPU head node\n",
    "en_sentence = raw_jmbt22_datasets[\"train\"][\"translation.en\"]\n",
    "tl_sentence = raw_jmbt22_datasets[\"train\"][\"translation.tl\"]\n",
    "\n",
    "with open(\"jmbt22_tatoeba-en-tgl.en\", \"w\") as file:\n",
    "    for row in en_sentence:\n",
    "        if len(row) != 0:\n",
    "            file.write(str(row) + '\\n')\n",
    "\n",
    "with open(\"jmbt22_tatoeba-en-tgl.tl\", \"w\") as file:\n",
    "    for row in tl_sentence:\n",
    "        if len(row) != 0:\n",
    "            file.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b874554-9437-47e3-ae92-66607a6b7cb7",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606e5317-c411-4d4a-8cab-cb634ad2fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jmbt22_tatoeba-en-tgl.en') as f:\n",
    "    lines_en = f.readlines()\n",
    "\n",
    "with open('jmbt22_tatoeba-en-tgl.tl') as f:\n",
    "    lines_tgl = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990ba66e-4d04-428c-8504-dcf0e0315a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300\n",
      "7300\n"
     ]
    }
   ],
   "source": [
    "print(len(lines_en))\n",
    "print(len(lines_tgl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b022bc-dafc-4630-9f7e-cfe4eddd8034",
   "metadata": {},
   "source": [
    "## Inference and Evaluation English To Tagalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fa301f-6cb0-4707-8eba-fec3fa3dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dba4d42-2cff-4747-a04c-f48a13c90c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7300/7300 [37:17<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "results_eng2tal = []\n",
    "'''\n",
    "#st = time.time()\n",
    "#print(\"infer time per sample \", idx, \", \" , time.time() - st , \"sec\")\n",
    "'''\n",
    "\n",
    "for idx, line in enumerate(tqdm(lines_en)): \n",
    "    translated_text, _, _ = translator.predict(line, \"t2tt\", 'tgl', src_lang='eng')\n",
    "    results_eng2tal.append(str(translated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a9396a3-ca66-4137-a494-ba365a59bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jmbt22_tatoeba-en-tgl.pred.eng2tgl\", \"w\") as file:\n",
    "    for row in results_eng2tal:\n",
    "        if len(row) != 0:\n",
    "            file.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d671da08-88c0-45a6-be5b-1205629f0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 23.8,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"54.5/29.1/18.0/11.2 (BP = 1.000 ratio = 1.131 hyp_len = 58860 ref_len = 52063)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sacrebleu jmbt22_tatoeba-en-tgl.tl < jmbt22_tatoeba-en-tgl.pred.eng2tgl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a057a4d-f10d-49f2-ace3-51da22a30d77",
   "metadata": {},
   "source": [
    "## Inference and Evaluation Tagalog to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d4b54c-163d-4429-9723-04bcb41e6e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7300/7300 [31:40<00:00,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "results_tal2eng = []\n",
    "\n",
    "for idx, line in enumerate(tqdm(lines_tgl)): \n",
    "    translated_text, _, _ = translator.predict(line, \"t2tt\", 'eng', src_lang='tgl')\n",
    "    results_tal2eng.append(translated_text)\n",
    "\n",
    "with open(\"jmbt22_tatoeba-en-tgl.pred.tgl2eng\", \"w\") as file:\n",
    "    for row in results_tal2eng:\n",
    "        if len(row) != 0:\n",
    "            file.write(str(row) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d40240-5062-4d22-9403-40ca0955a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 41.1,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"68.3/46.4/34.7/26.7 (BP = 0.994 ratio = 0.994 hyp_len = 52760 ref_len = 53094)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sacrebleu jmbt22_tatoeba-en-tgl.en < jmbt22_tatoeba-en-tgl.pred.tgl2eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b967d0d-5833-49ec-a93b-47d6b79f941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model_checkpoint = \"facebook/seamless-m4t-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
